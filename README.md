# TabRL: Exploring LLM-Driven Reinforcement Learning in Your Browser

TabRL is a project exploring the integration of Large Language Models (LLMs) with Reinforcement Learning (RL) to tackle complex MuJoCo physics tasks directly in your web browser. We are investigating how LLMs can assist in generating and potentially optimizing reward functions, moving towards more AI-driven approaches in RL.

Our current development efforts are centered on integrating Anthropic's Claude. We aim to establish a solid foundation for this integration, with the aspiration to later explore and potentially incorporate other leading LLMs such as OpenAI's GPT series and Google's Gemini. This work is being developed with the AI Engineer World's Fair in mind as a potential venue to showcase these capabilities. The goal is to provide an accessible, interactive platform for engineers to experiment with LLM-guided RL.

**üé• Original Demo Video (Illustrates Core Tech): https://tinyurl.com/tabrl**

![Original Demo Screenshot](./workspace/current%20dashboard.png)

## üåü Vision: The LLM Meta-RL Battle Arena

The ultimate aim is to present a live, interactive "battle" where different LLMs (Claude, OpenAI, Gemini) simultaneously:
1.  **Design Reward Functions:** Each LLM proposes unique reward functions for a humanoid agent.
2.  **Drive Training:** Agents are trained in parallel using these LLM-generated rewards.
3.  **Compare Performance:** Visualize in real-time which LLM's strategy leads to faster learning, more robust policies, or more creative solutions.

This provides a transparent and engaging way to compare the "reasoning" and "creativity" of different LLMs in a complex, dynamic control problem.

## üöÄ Quick Start (Towards the Vision)

### 1. Start the Unified LLM Proxy (Required for LLM Features)
*(This is the server-side component you'll be developing/refining to handle requests to Claude, OpenAI, and Gemini)*
```bash
# Example: Start your unified LLM proxy (e.g., llm-proxy.js)
node workspace/llm-proxy.js 
```

### 2. Open the Demo
```bash
# Phase 1: Single LLM Meta-Learning Demo (User Selects Provider)
open http://localhost:8080/workspace/meta-rl-demo.html

# Future: Multi-LLM Battle Demo
# open http://localhost:8080/workspace/meta-rl-battle.html
```

### 3. Configure LLM API Keys (Optional but Recommended)
Edit `workspace/llm-config.js` (you'll create/rename this) and add your API keys:
```javascript
window.LLM_CONFIG = {
    claude: {
        apiKey: 'YOUR_ANTHROPIC_API_KEY_HERE',
        model: 'claude-opus-4-20250514',
    },
    openai: {
        apiKey: 'YOUR_OPENAI_API_KEY_HERE',
        model: 'gpt-4.1',
    },
    gemini: {
        apiKey: 'YOUR_GOOGLE_GEMINI_API_KEY_HERE',
        model: 'gemini-2.5-pro', 
    },
    // Shared settings
    maxTokens: 2000 
};
```
*(Note: Actual API key handling will be done securely by the `llm-proxy.js` on the server-side. The client might only need to know which providers are available if keys are configured in the proxy.)*

## üéØ Core Features

### Browser-Based RL Training
- **Real-time policy gradient learning** - Train neural networks directly in the browser.
- **WebAssembly MuJoCo physics** - Full physics simulation at 1000+ Hz.
- **Multi-threaded architecture** - Web Workers for parallel training.
- **Zero installation** - Just open in a browser!

### Multi-LLM-Driven Reinforcement Learning
- **LLM-Generated Reward Functions**: AI models (Claude, OpenAI, Gemini) design reward functions based on high-level task descriptions.
- **Iterative Improvement**: LLMs can (potentially) analyze performance and suggest hyperparameter changes or reward modifications.
- **Population-Based Training**: Multiple policies can be trained in parallel, each potentially guided by a different LLM or strategy.
- **Comparative Analysis**: Directly compare the efficacy of reward functions generated by different LLMs.

### Visualization
- **2D stick figure rendering** - Real-time robot state visualization.
- **3D Three.js views** - Click any environment for detailed 3D view.
- **Performance graphs** - Track learning progress across iterations and LLM providers.
- **Live statistics** - FPS, rewards, episode counts.

## üó∫Ô∏è Roadmap to the AI Engineer World's Fair

This project is on an ambitious trajectory. Here‚Äôs how we get to the main event:

*   **‚úÖ Phase 0: Foundational Work (Partially Complete)**
    *   Stabilize core RL training loop for a humanoid task.
    *   Research API capabilities and integration patterns for Claude, OpenAI, and Gemini.
    *   Develop the initial server-side unified `llm-proxy` to handle requests to at least one LLM provider (e.g., Claude) and manage API keys securely.

*   **‚û°Ô∏è Phase 1: `meta-rl-demo.html` - Single Selectable LLM (In Progress)**
    *   Create a UI in `meta-rl-demo.html` allowing users to select one LLM provider (Claude, OpenAI, Gemini) from a dropdown.
    *   The selected LLM generates reward functions for the existing 4-policy meta-RL setup.
    *   Client-side JavaScript calls the `llm-proxy` with the selected provider.

*   **Phase 2: `llm-service.js` - Client-Side Abstraction**
    *   Develop `llm-service.js`, a client-side abstraction layer.
    *   This service will provide a standardized interface for requesting reward functions, regardless of the chosen LLM provider.
    *   It will format requests for the `llm-proxy` and parse its responses.

*   **Phase 3: Full Multi-LLM Proxy Integration**
    *   Enhance the server-side `llm-proxy` to robustly handle requests for all three target LLMs (Claude, OpenAI, Gemini).
    *   Implement secure API key management, request routing, and error handling for each provider.
    *   Standardize response formats from the proxy where possible.

*   **Phase 4: `meta-rl-battle.html` - The Grand Demo**
    *   Design and build the `meta-rl-battle.html` interface.
    *   This will allow simultaneous operation of multiple LLMs. Examples:
        *   Each LLM designs a reward for one of N parallel training arenas.
        *   A "tournament" mode where agents trained with LLM A's rewards compete against agents trained with LLM B's rewards.
    *   Focus on clear, engaging visualizations for comparison.

*   **Phase 5: Polish, Performance, & Packaging**
    *   Intensive testing of all components.
    *   Performance optimization for smooth live demo experience.
    *   UI/UX refinement for clarity and impact.
    *   Create a downloadable package/instructions for attendees to run the demo themselves.

## üèóÔ∏è Architecture Overview (Evolving)

The core parallel simulation architecture remains, with the LLM interaction layer being significantly enhanced:

```
Browser (Main Thread: UI, Orchestration, llm-service.js)
    |                                ‚ñ≤
    | (Requests: provider, prompt)   | (Responses: generated rewards)
    v                                |
LLM Proxy Server (localhost:3001/llm-proxy) -- Manages:
    |                                         - API Keys
    |                                         - Routing to LLM APIs
    |                                         - CORS
    +------------------+------------------+
    |                  |                  |
    v                  v                  v
Claude API        OpenAI API        Gemini API
```
*(Worker architecture for MuJoCo simulation remains as previously diagrammed)*

### Key Components (Planned/Evolving)
- **`meta-rl-demo.html` / `meta-rl-battle.html`**: Main demo interfaces.
- **`llm-service.js`**: Client-side module for standardized LLM interactions via the proxy.
- **`llm-config.js`**: Client-side configuration for LLM provider details (if needed, primary key management is server-side).
- **`llm-proxy.js` (Server-Side)**: Your Node.js (or other) application that acts as the secure gateway to all LLM APIs.
- **`browser-rl.js`**: Core policy gradient RL implementation.
- **`mujoco-orchestrator-v3.js`**: Manages worker pool for MuJoCo.
- *(Other existing visualization and worker modules)*

## üß† How It Works (LLM Integration)

1.  **Task Definition**: The user (or demo script) defines a high-level goal (e.g., "make the humanoid walk forward quickly and efficiently while maintaining balance").
2.  **LLM Invocation**: `llm-service.js` sends this goal, along with context about the robot's observations and actions, to the `llm-proxy`.
3.  **Proxy Routing**: The `llm-proxy` forwards the request to the selected LLM provider (Claude, OpenAI, or Gemini).
4.  **Reward Generation**: The LLM processes the request and generates a JavaScript function string representing the reward logic.
5.  **Training**: This generated reward function is used by `browser-rl.js` to train the agent's policy in the WebAssembly MuJoCo simulation.
6.  **Iteration (Meta-Learning)**: For the "battle" demo, multiple LLMs will generate different reward functions, and their resulting agent performances will be compared.

## üìä Performance
(Performance metrics for the core simulation engine remain as previously stated. LLM interaction performance will depend on API latencies and proxy efficiency.)

- **Training Speed**: 50-500 episodes converge to stable walking (with a good reward).
- **Physics Rate**: 1000+ steps/second per environment.
- **Rendering**: 60-120 FPS with multiple environments.

## üõ†Ô∏è Development

### Docker Setup (For MuJoCo WASM build environment if needed)
```bash
# Build and run
docker-compose up --build -d

# Access container
docker exec -it mujoco-wasm-container bash

# Rebuild WASM
docker exec -it mujoco-wasm-container build
```

### Project Structure (Target)
```
workspace/
‚îú‚îÄ‚îÄ meta-rl-demo.html          # Phase 1: Selectable LLM demo
‚îú‚îÄ‚îÄ meta-rl-battle.html        # Phase 4: Multi-LLM comparison demo
‚îú‚îÄ‚îÄ js/
‚îÇ   ‚îú‚îÄ‚îÄ llm-service.js         # Client-side LLM abstraction
‚îÇ   ‚îú‚îÄ‚îÄ browser-rl.js          # RL algorithm
‚îÇ   ‚îú‚îÄ‚îÄ mujoco-orchestrator-v3.js # Worker management
‚îÇ   ‚îú‚îÄ‚îÄ visualization-2d.js    # 2D rendering
‚îÇ   ‚îú‚îÄ‚îÄ threejs-modal.js       # 3D visualization
‚îÇ   ‚îî‚îÄ‚îÄ llm-config.js          # LLM endpoint/model configs (keys managed by proxy)
‚îú‚îÄ‚îÄ llm-proxy.js               # SERVER-SIDE: Unified proxy for LLM APIs
‚îî‚îÄ‚îÄ assets/
    ‚îî‚îÄ‚îÄ ... (images, models)
```

## üöß Current Status
Actively under development towards the AI Engineer World's Fair! Focusing on Phase 1: enabling single LLM selection in `meta-rl-demo.html` and robust `llm-proxy` interaction. See `PROJECT-STATUS.md` for detailed progress.

## ü§ù Contributing & Collaboration
This is an ambitious open-source endeavor. Contributions, ideas, and feedback are welcome as we build towards this exciting public demonstration!

## üìö Further Reading & Resources

Here are some resources that provide more context or are related to the technologies used in this project:

- [RL System Overview](./RL_SYSTEM_OVERVIEW.md) - A detailed explanation of the current reinforcement learning implementation (`browser-rl.js`).

*   **MuJoCo Physics Engine:**
    *   [Official MuJoCo Website](https://mujoco.org/) - Main page for the MuJoCo physics simulator.
    *   [MuJoCo Documentation](https://mujoco.readthedocs.io/en/latest/) - Detailed documentation on using MuJoCo.
    *   [DeepMind's Acquisition of MuJoCo](https://deepmind.google/discover/blog/mujoco-for-all/) - Blog post about MuJoCo becoming open-source.
*   **Reinforcement Learning (RL):**
    *   [Sutton and Barto, Reinforcement Learning: An Introduction (2nd Edition)](http://incompleteideas.net/book/the-book-2nd.html) - The foundational textbook for RL.
    *   [OpenAI Spinning Up in Deep RL](https://spinningup.openai.com/en/latest/) - A great educational resource by OpenAI for learning about deep RL.
    *   [Stable Baselines3](https://stable-baselines3.readthedocs.io/en/master/) - A popular library of reliable RL algorithm implementations (though this project uses its own).
*   **WebAssembly (WASM):**
    *   [WebAssembly Official Site](https://webassembly.org/) - Learn more about WASM.
    *   [MDN Web Docs on WebAssembly](https://developer.mozilla.org/en-US/docs/WebAssembly) - Comprehensive documentation for web developers.
*   **Actor-Critic Methods (relevant to the diagram):**
    *   [Lil'Log: Policy Gradient Algorithms](https://lilianweng.github.io/posts/2018-04-08-policy-gradient/) - A good blog post explaining policy gradients and actor-critic methods.coming open-source.
*   **Reinforcement Learning (RL):**
    *   [Sutton and Barto, Reinforcement Learning: An Introduction (2nd Edition)](http://incompleteideas.net/book/the-book-2nd.html) - The foundational textbook for RL.
    *   [OpenAI Spinning Up in Deep RL](https://spinningup.openai.com/en/latest/) - A great educational resource by OpenAI for learning about deep RL.
    *   [Stable Baselines3](https://stable-baselines3.readthedocs.io/en/master/) - A popular library of reliable RL algorithm implementations (though this project uses its own).
*   **WebAssembly (WASM):**
    *   [WebAssembly Official Site](https://webassembly.org/) - Learn more about WASM.
    *   [MDN Web Docs on WebAssembly](https://developer.mozilla.org/en-US/docs/WebAssembly) - Comprehensive documentation for web developers.
*   **Actor-Critic Methods (relevant to the diagram):**
    *   [Lil'Log: Policy Gradient Algorithms](https://lilianweng.github.io/posts/2018-04-08-policy-gradient/) - A good blog post explaining policy gradients and actor-critic methods.
*   **This Project's Inspirations (Hypothetical, can be customized):**
    *   [Example: "Massively Parallel Methods for Deep Reinforcement Learning"](https://arxiv.org/abs/1507.04296) - (Replace with actual papers or projects if they exist)
    *   [Example: "Automated Curriculum Learning for RL"](https://arxiv.org/abs/1707.00183) - (Replace with actual papers or projects if they exist)
## üôè Acknowledgments
{{ ... }}
- [MuJoCo WASM](https://github.com/zalo/mujoco_wasm) for physics engine
- [Anthropic Claude](https://www.anthropic.com/) for LLM capabilities
- Browser ML community for inspiration

## üì¨ Contact

- Hackathon Team: [aditya@bestparents.com], [richa.flutr@gmail.com]
- Project Leads: Aditya, Richa
- GitHub: [ninjaa] [richafltr]

---

*üèÜ CV x AIWF Hackathon 2025 - Statement 3: Reasoning and Task RL*

*Built with ‚ù§Ô∏è using Claude Opus 4, Windsurf, and the power of browser-based ML*
